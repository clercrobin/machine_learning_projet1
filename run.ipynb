{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython import display\n",
    "from proj1_helpers import *\n",
    "import costs\n",
    "from split_data import *\n",
    "from least_squares import *\n",
    "import standardize\n",
    "from gradient_descent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate a model\n",
    "\n",
    "def prediction(y, tX, w_star):\n",
    "    \"\"\"Evaluates a model in a friendly manner\"\"\"\n",
    "    pred = np.dot(tX, w_star)\n",
    "\n",
    "    pred[pred > 0] = 1\n",
    "    pred[pred <= 0] = -1\n",
    "\n",
    "    right = np.sum(pred == y)\n",
    "    wrong = len(pred) - right\n",
    "\n",
    "    print(\"Good prediction: %i/%i (%.3f%%)\\nWrong prediction: %i/%i (%.3f%%)\" %\n",
    "          (right, len(y), 100.0 * float(right) / float(len(y)),\n",
    "           wrong, len(y), 100.0 * float(wrong) / float(len(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the whole data\n",
    "\n",
    "y_train, x_train, ids_train, headers = load_csv_data('data/train.csv')\n",
    "y_test, x_test, ids_test, headers_test = load_csv_data('data/test.csv')\n",
    "\n",
    "# print(headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n"
     ]
    }
   ],
   "source": [
    "# Correlation analysis\n",
    "from scipy.stats.stats import pearsonr\n",
    "from numpy import corrcoef\n",
    "\n",
    "print(x_train.shape)\n",
    "correlation_matrix = np.zeros((x_train.shape[1],x_train.shape[1]))\n",
    "for i in range(x_train.shape[1]):\n",
    "    for j in range(x_train.shape[1]):\n",
    "        #print(headers[i+2], headers[j+2])\n",
    "        corr = corrcoef(x_train[:,i], x_train[:,j])\n",
    "        #print(corr[1,0])\n",
    "        correlation_matrix[i,j] = corr[1,0]\n",
    "\n",
    "\n",
    "#print(correlation_matrix)\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "99913\n",
      "Nombre de variables restantes : 18\n",
      "Loss = 10.295381\n",
      "1\n",
      "77544\n",
      "Nombre de variables restantes : 22\n",
      "Loss = 10.735226\n",
      "2\n",
      "72543\n",
      "Nombre de variables restantes : 29\n",
      "Loss = 0.265805\n"
     ]
    }
   ],
   "source": [
    "from build_polynomial import build_poly\n",
    "from least_squares import least_squares\n",
    "from ridge_regression import ridge_regression\n",
    "\n",
    "# REALY MAKES THE PREDICTION\n",
    "\n",
    "#y_train, x_train, ids_train, headers = load_csv_data('data/train.csv')\n",
    "#y_test, x_test, ids_test, headers_test = load_csv_data('data/test.csv')\n",
    "\n",
    "\n",
    "ratio = 0.8\n",
    "\n",
    "for deg in range(10,11):\n",
    "    for i in range (3):\n",
    "        print(i)\n",
    "        jetMaskTrain = x_train[:,22]==i\n",
    "        jetMaskTest = x_test[:,22]==i\n",
    "        if (i == 2):\n",
    "            jetMaskTrain = np.asarray(x_train[:,22]==i) + np.asarray(x_train[:,22]==3) \n",
    "            jetMaskTest = np.asarray(x_test[:,22]==i) + np.asarray(x_test[:,22]==3) \n",
    "        print(len(x_train[jetMaskTrain]))\n",
    "        trainProcessed, testProcessed = processing(x_train[jetMaskTrain], x_test[jetMaskTest], jet_mod = True, jet_num=i)\n",
    "        #show_x(trainProcessed)\n",
    "        #show_x(testProcessed)\n",
    "\n",
    "        #jetDividedTrainProcessed.append(trainProcessed)\n",
    "        #jetDividedTestProcessed.append(testProcessed)\n",
    "\n",
    "\n",
    "        yJetTrain = y_train[jetMaskTrain]\n",
    "        yJetTest = y_test[jetMaskTest]\n",
    "        #x_train2, y_train2, x_test2, y_test2 = split_data(trainProcessed, yJetTrain, ratio)\n",
    "        x_train2, y_train2, x_test2, y_test2 = trainProcessed, yJetTrain,testProcessed,yJetTest\n",
    "        trainProcessedPoly = build_poly(x_train2, deg)\n",
    "        testProcessedPoly = build_poly(x_test2,deg)\n",
    "        loss, w_star = ridge_regression(yJetTrain, trainProcessedPoly,0.00001)\n",
    "        print(\"Loss = %f\"%(loss))\n",
    "        y_pred = predict_labels(w_star, testProcessedPoly)\n",
    "        \n",
    "\n",
    "        create_csv_submission(ids_test[jetMaskTest], y_pred, \"LeastSquaresPoly\"+str(i))\n",
    "        #loss, w_star = least_squares(y_train2, trainProcessedPoly)\n",
    "        #print(\"Loss = %f\"%(loss))\n",
    "        #prediction(y_test2, testProcessedPoly, w_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#y_train, x_train, ids_train, headers = load_csv_data('data/train.csv')\n",
    "#y_test, x_test, ids_test, headers_test = load_csv_data('data/test.csv')\n",
    "\n",
    "#print(headers)\n",
    "\n",
    "\n",
    "def processing(x_train, x_test, long_tails = [0,1,2,3,5,8,9,10,13,16,19,21,23,26,29], jet_mod = False, jet_num=0):\n",
    "    \n",
    "    \n",
    "    # Log transform all the long tails\n",
    "    correct_mask_train = x_train!=-999\n",
    "    correct_mask_test = x_test!=-999\n",
    "    for i in range(len(x_train[0])):    \n",
    "        array_tr = x_train[correct_mask_train[:,i],i] # Only the correct Values\n",
    "        array_te = x_test[correct_mask_test[:,i],i] # Only the correct Values\n",
    "        if i in long_tails: # We log them if they have long tails\n",
    "            array_tr = np.log(array_tr+1)\n",
    "            array_te = np.log(array_te+1)\n",
    "            \n",
    "            \n",
    "    if jet_mod:\n",
    "        if jet_num == 0:\n",
    "            jetFeaturesExcluded = [4,5,6,12,22,23,24,25,26,27,28,29]\n",
    "        elif jet_num == 1:\n",
    "            jetFeaturesExcluded = [4,5,6,12,22,26,27,28]\n",
    "        else :\n",
    "            jetFeaturesExcluded = [22]\n",
    "    else:\n",
    "        jetFeaturesExcluded = []\n",
    "        \n",
    "    all_indices = np.arange(x_train.shape[1])\n",
    "    excepted = np.setdiff1d(all_indices,jetFeaturesExcluded)\n",
    "    x_test = x_test[:,excepted]\n",
    "    x_train = x_train[:,excepted]\n",
    "    print(\"Nombre de variables restantes : \" + str(len(x_train[0])))\n",
    "    #print(x_train)\n",
    "\n",
    "    \n",
    "    #x_train_extended = x_train.copy()\n",
    "    missing_mask_train = x_train==-999\n",
    "    correct_mask_train = x_train!=-999\n",
    "    \n",
    "    #x_test_extended = x_test.copy()\n",
    "    missing_mask_test = x_test==-999\n",
    "    correct_mask_test = x_test!=-999\n",
    "\n",
    "\n",
    "    for i in range(len(x_train[0])):\n",
    "\n",
    "        array_tr = x_train[correct_mask_train[:,i],i] # Only the correct Values\n",
    "        array_te = x_test[correct_mask_test[:,i],i] # Only the correct Values\n",
    "\n",
    "\n",
    "        arraytr, mean_train, std_train = (standardize.standardize(array_tr))\n",
    "        arrayte, mean_train, std_train = (standardize.standardize(array_te, mean_train, std_train))\n",
    "        x_train[correct_mask_train[:,i],i] = arraytr\n",
    "        x_test[correct_mask_test[:,i],i] = arrayte\n",
    "        #plt.hist(arraytr, 10)\n",
    "        #plt.title(\"Variable %i\"%(i))\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "    x_train[missing_mask_train] = 0\n",
    "    x_test[missing_mask_test] = 0\n",
    "    \n",
    "    # Now everything is normalized, let us compute some products and differences. They will be polynomial transformed too\n",
    "    angle = [15,18,20]\n",
    "    \n",
    "    if jet_mod and (jet_num == 0 or jet_num == 1):\n",
    "        angle = [12,15,17]\n",
    "    diff1x_train = np.abs(x_train[:,angle[0]] - x_train[:,angle[1]]).reshape((len(x_train),1))\n",
    "    diff2x_train = np.abs(x_train[:,angle[0]] - x_train[:,angle[2]]).reshape((len(x_train),1))\n",
    "    diff3x_train = np.abs(x_train[:,angle[2]] - x_train[:,angle[1]]).reshape((len(x_train),1))\n",
    "    \n",
    "    diff1x_test = np.abs(x_test[:,angle[0]] - x_test[:,angle[1]]).reshape((len(x_test),1))\n",
    "    diff2x_test = np.abs(x_test[:,angle[0]] - x_test[:,angle[2]]).reshape((len(x_test),1))\n",
    "    diff3x_test = np.abs(x_test[:,angle[2]] - x_test[:,angle[1]]).reshape((len(x_test),1))\n",
    "    \n",
    "    #print(diff1x_train.shape)\n",
    "    #print(diff2x_train.shape)\n",
    "    #print(diff3x_train.shape)\n",
    "    #print(x_train.shape)\n",
    "    x_train = np.hstack((x_train, diff1x_train,diff2x_train,diff3x_train))\n",
    "    x_test = np.hstack((x_test, diff1x_test,diff2x_test,diff3x_test))\n",
    "    \n",
    "    taille = len(x_train[0])\n",
    "    for i in range(taille):\n",
    "        for j in range(i):\n",
    "            new_column_train =(x_train[:,i]*x_train[:,j]).reshape((len(x_train),1))\n",
    "            x_train = np.hstack((x_train,new_column_train))\n",
    "            new_column_test = (x_test[:,i]*x_test[:,j]).reshape((len(x_test),1))\n",
    "            x_test = np.hstack((x_test,new_column_test))\n",
    "    \n",
    "    return x_train,x_test\n",
    "\n",
    "def show_x(x):\n",
    "    for i in range(len(x[0])):\n",
    "        array = x[:,i]\n",
    "        plt.hist(array, 250)\n",
    "        plt.title(\"Variable %i: %s\"%(i, headers[i+2]))\n",
    "        plt.show()\n",
    "    return x\n",
    "    \n",
    "\n",
    "#x_train, x_test = processing(x_train, x_test)\n",
    "#show_x(x_test)\n",
    "\n",
    "#print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degré : 2\n",
      "Jet : 0\n",
      "Nombre de variables restantes : 18\n",
      "Good prediction: 16760/19983 (83.871%)\n",
      "Wrong prediction: 3223/19983 (16.129%)\n",
      "Jet : 1\n",
      "Nombre de variables restantes : 22\n",
      "Good prediction: 12144/15509 (78.303%)\n",
      "Wrong prediction: 3365/15509 (21.697%)\n",
      "Jet : 2\n",
      "Nombre de variables restantes : 29\n",
      "Good prediction: 11760/14509 (81.053%)\n",
      "Wrong prediction: 2749/14509 (18.947%)\n",
      "Degré : 4\n",
      "Jet : 0\n",
      "Nombre de variables restantes : 18\n",
      "Good prediction: 16833/19983 (84.237%)\n",
      "Wrong prediction: 3150/19983 (15.763%)\n",
      "Jet : 1\n",
      "Nombre de variables restantes : 22\n",
      "Good prediction: 12129/15509 (78.206%)\n",
      "Wrong prediction: 3380/15509 (21.794%)\n",
      "Jet : 2\n",
      "Nombre de variables restantes : 29\n",
      "Good prediction: 11978/14509 (82.556%)\n",
      "Wrong prediction: 2531/14509 (17.444%)\n",
      "Degré : 6\n",
      "Jet : 0\n",
      "Nombre de variables restantes : 18\n",
      "Good prediction: 16809/19983 (84.116%)\n",
      "Wrong prediction: 3174/19983 (15.884%)\n",
      "Jet : 1\n",
      "Nombre de variables restantes : 22\n",
      "Good prediction: 12456/15509 (80.315%)\n",
      "Wrong prediction: 3053/15509 (19.685%)\n",
      "Jet : 2\n",
      "Nombre de variables restantes : 29\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-bfdcc8298c6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainProcessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myJetTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#x_train2, y_train2, x_test2, y_test2 = trainProcessed, yJetTrain,testProcessed,yJetTest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtrainProcessedPoly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mtestProcessedPoly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleast_squares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainProcessedPoly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/robinclerc/Dropbox/EPFL/Machine learning/ML_course/projects/project1/scripts/projet/build_polynomial.py\u001b[0m in \u001b[0;36mbuild_poly\u001b[0;34m(x, degree)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/anaconda/lib/python3.6/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mcolumn_stack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from build_polynomial import build_poly\n",
    "from least_squares import least_squares\n",
    "from ridge_regression import ridge_regression\n",
    "\n",
    "# EVALUATE A MODEL\n",
    "\n",
    "#y_train, x_train, ids_train, headers = load_csv_data('data/train.csv')\n",
    "#y_test, x_test, ids_test, headers_test = load_csv_data('data/test.csv')\n",
    "\n",
    "\n",
    "ratio = 0.8\n",
    "\n",
    "for deg in range(2,18,2):\n",
    "    print(\"Degré : \" + str(deg))\n",
    "    for i in range (3):\n",
    "        print(\"Jet : \" + str(i))\n",
    "        jetMaskTrain = x_train[:,22]==i\n",
    "        jetMaskTest = x_test[:,22]==i\n",
    "        if (i == 2):\n",
    "            jetMaskTrain = np.asarray(x_train[:,22]==i) + np.asarray(x_train[:,22]==3) \n",
    "            jetMaskTest = np.asarray(x_test[:,22]==i) + np.asarray(x_test[:,22]==3) \n",
    "        #print(len(x_train[jetMaskTrain]))\n",
    "        trainProcessed, testProcessed = processing(x_train[jetMaskTrain], x_test[jetMaskTest], jet_mod = True, jet_num=i)\n",
    "        #show_x(trainProcessed)\n",
    "        #show_x(testProcessed)\n",
    "\n",
    "        #jetDividedTrainProcessed.append(trainProcessed)\n",
    "        #jetDividedTestProcessed.append(testProcessed)\n",
    "\n",
    "\n",
    "        yJetTrain = y_train[jetMaskTrain]\n",
    "        yJetTest = y_test[jetMaskTest]\n",
    "        x_train2, y_train2, x_test2, y_test2 = split_data(trainProcessed, yJetTrain, ratio)\n",
    "        #x_train2, y_train2, x_test2, y_test2 = trainProcessed, yJetTrain,testProcessed,yJetTest\n",
    "        trainProcessedPoly = build_poly(x_train2, deg)\n",
    "        testProcessedPoly = build_poly(x_test2,deg)\n",
    "        loss, w_star = least_squares(y_train2, trainProcessedPoly)\n",
    "        #print(\"Loss = %f\"%(loss))\n",
    "        y_pred = predict_labels(w_star, testProcessedPoly)\n",
    "        \n",
    "\n",
    "        #create_csv_submission(ids_test[jetMaskTest], y_pred, \"LeastSquaresPoly\"+str(i))\n",
    "        prediction(y_test2, testProcessedPoly, w_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6\n",
      "0\n",
      "1\n",
      "15\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from ridge_regression import ridge_regression\n",
    "from build_polynomial import build_poly\n",
    "from plots import cross_validation_visualization\n",
    "from build_k_indices import build_k_indices\n",
    "from cross_validation import cross_validation\n",
    "import numpy as np\n",
    "\n",
    "def cross_validation_demo():\n",
    "    seed = 26\n",
    "    k_fold = 2\n",
    "    \n",
    "    lambdas = np.logspace(-5, -2, 2)\n",
    "    degrees = np.linspace(6, 15,2)\n",
    "    \n",
    "    y_train, x_train, ids_train, headers = load_csv_data('data/train.csv')\n",
    "    y_test, x_test, ids_test, headers_test = load_csv_data('data/test.csv')\n",
    "    x_train, x_test = processing(x_train, x_test)\n",
    "    \n",
    "    losses = np.zeros((len(lambdas), len(degrees)))\n",
    "\n",
    "\n",
    "\n",
    "    y = y_train\n",
    "    x = x_train\n",
    "    \n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    #print(k_indices)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # cross validation: TODO\n",
    "    # ***************************************************\n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        print(ind)\n",
    "\n",
    "        for ind_deg, degree in enumerate(degrees):\n",
    "            degree = int(degree)\n",
    "            print(degree)\n",
    "            mse_tr_ = []\n",
    "            mse_te_ = []\n",
    "            x = build_poly(x_train, degree)\n",
    "            y = y_train\n",
    "            for k in range(k_fold):\n",
    "                print(k)\n",
    "                #print(k_indices[k])\n",
    "                mse_tr_i, mse_te_i = cross_validation(y, x, k_indices, k, lambda_, degree)\n",
    "                mse_tr_.append(mse_tr_i)\n",
    "                mse_te_.append(mse_te_i)\n",
    "            losses[ind,ind_deg] = np.sqrt(2*np.asarray(mse_te_).mean())\n",
    "            #rmse_tr.append(np.sqrt(2*np.asarray(mse_tr_).mean()))\n",
    "            #rmse_te.append(np.sqrt(2*np.asarray(mse_te_).mean()))\n",
    "    #print(rmse_tr)\n",
    "    #print(rmse_te)\n",
    "    #cross_validation_visualization(lambdas, rmse_tr, rmse_te)\n",
    "    min_row, min_col = np.unravel_index(np.argmin(losses), losses.shape)\n",
    "    print(losses[min_row, min_col], lambdas[min_row], degrees[min_col])\n",
    "\n",
    "cross_validation_demo()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 420)\n",
      "Loss = 0.266692\n",
      "Good prediction: 41103/50000 (82.206%)\n",
      "Wrong prediction: 8897/50000 (17.794%)\n"
     ]
    }
   ],
   "source": [
    "from build_polynomial import build_poly\n",
    "from ridge_regression import ridge_regression\n",
    "\n",
    "\n",
    "ratio = 0.8\n",
    "lambda_ = 0.001\n",
    "y_train, x_train, ids_train, headers = load_csv_data('data/train.csv')\n",
    "y_test, x_test, ids_test, headers_test = load_csv_data('data/test.csv')\n",
    "x_train, x_test = processing(x_train, x_test)\n",
    "x_train2, y_train2, x_test2, y_test2 = split_data(x_train, y_train, ratio)\n",
    "x_train2 = build_poly(x_train2,14)\n",
    "x_test2 = build_poly(x_test2,14)\n",
    "print(x_train2.shape)\n",
    "\n",
    "loss, w_star = ridge_regression(y_train2, x_train2, lambda_)\n",
    "print(\"Loss = %f\"%(loss))\n",
    "prediction(y_test2, x_test2, w_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-829a163a730e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbuild_polynomial\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_csv_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_csv_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Robin\\Dropbox\\EPFL\\Machine learning\\ML_course\\projects\\project1\\scripts\\proj1_helpers.py\u001b[0m in \u001b[0;36mload_csv_data\u001b[1;34m(data_path, sub_sample)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;34m\"\"\"Loads data and returns y (class labels), tX (features) and ids (event ids)\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0minput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Robin\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows)\u001b[0m\n\u001b[0;32m   1842\u001b[0m         rows = list(\n\u001b[0;32m   1843\u001b[0m             zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n\u001b[1;32m-> 1844\u001b[1;33m                   for (i, conv) in enumerate(converters)]))\n\u001b[0m\u001b[0;32m   1845\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         rows = list(\n",
      "\u001b[1;32mC:\\Users\\Robin\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1842\u001b[0m         rows = list(\n\u001b[0;32m   1843\u001b[0m             zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n\u001b[1;32m-> 1844\u001b[1;33m                   for (i, conv) in enumerate(converters)]))\n\u001b[0m\u001b[0;32m   1845\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         rows = list(\n",
      "\u001b[1;32mC:\\Users\\Robin\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mloose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m         rows = list(\n\u001b[1;32m-> 1843\u001b[1;33m             zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n\u001b[0m\u001b[0;32m   1844\u001b[0m                   for (i, conv) in enumerate(converters)]))\n\u001b[0;32m   1845\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Robin\\Anaconda3\\lib\\site-packages\\numpy\\lib\\_iotools.py\u001b[0m in \u001b[0;36m_loose_call\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_loose_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from build_polynomial import build_poly\n",
    "\n",
    "y_train, x_train, ids_train, headers = load_csv_data('data/train.csv')\n",
    "y_test, x_test, ids_test, headers_test = load_csv_data('data/test.csv')\n",
    "x_train, x_test = processing(x_train, x_test)\n",
    "x_train2, y_train2, x_test2, y_test2 = x_train, y_train, x_test, y_test  #split_data(x_train, y_train, ratio)\n",
    "print(x_train2.shape)\n",
    "\n",
    "x_train2 = build_poly(x_train2,17)\n",
    "x_test2 = build_poly(x_test2,17)\n",
    "\n",
    "loss, w_star = least_squares(y_train2, x_train2)\n",
    "print(\"Loss = %f\"%(loss))\n",
    "y_pred = predict_labels(w_star, x_test2)\n",
    "\n",
    "create_csv_submission(ids_test, y_pred, \"LeastSquaresPoly7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 2\n",
    "gamma = 0.1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.ones((x_train.shape[1],1))\n",
    "\n",
    "# Start gradient descent.\n",
    "\n",
    "gradient_losses, gradient_ws = gradient_descent(y_train2, x_train2, w_initial, max_iters, gamma)\n",
    "\n",
    "\n",
    "# Print result\n",
    "\n",
    "prediction(y_test2, x_test2, gradient_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "rmse_tr = [321302705.32118189, 3081770291.9105225, 476655556.38870007, 6586530333.0643339, 3926785041.4215159, 1616028753.2465477, 3052424875.4092693, 754319853.14006972, 820583378.54368246, 17035954628.916489, 5638215798.1593828, 552445902.43237698, 1247083919.8717456, 523056402.48754984, 815035142.10989654, 1237961483.8206384, 472263250.85445482, 1128685585.2602913, 337359441.7431621, 444615308.73539412, 1187695089.0441186, 1154291756.4891524, 633935548.60643542, 893150866.4781518, 599195433.74783516, 501288433.01773316, 747877161.89168787, 949075067.35166752, 568752240.36924183, 500503541.8066045]\n",
    "rmse_te = [321459366.76115286, 3080249672.8730979, 475708961.98398209, 6580836712.3314152, 3924229065.938735, 1613714218.0849831, 3047141985.7805061, 752419169.80420673, 820506657.64361334, 17050315097.83621, 5652826434.3759661, 549735520.04158115, 1249299198.0115349, 523593309.05457181, 816846389.92515397, 1233223624.2504148, 472515141.34812337, 1125814263.3493133, 337950445.59918481, 442503614.14081073, 1187863323.660614, 1153379569.6909783, 633791488.363711, 892879869.87547123, 599439412.66542077, 501843482.74288714, 748023611.58240223, 950631904.87251222, 566716174.01105654, 501018160.37078071]\n",
    "\n",
    "print(np.argmin(rmse_te))\n",
    "i = 0\n",
    "for j in (np.logspace(-4, 0, 30)):\n",
    "    i +=1\n",
    "    if i==np.argmin(rmse_te):\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.asarray([3,2]) * np.asarray([3,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray([True, False, True]) + np.asarray([False, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Id' 'Prediction' 'DER_mass_MMC' 'DER_mass_transverse_met_lep'\n",
      " 'DER_mass_vis' 'DER_pt_h' 'DER_deltaeta_jet_jet' 'DER_mass_jet_jet'\n",
      " 'DER_prodeta_jet_jet' 'DER_deltar_tau_lep' 'DER_pt_tot' 'DER_sum_pt'\n",
      " 'DER_pt_ratio_lep_tau' 'DER_met_phi_centrality' 'DER_lep_eta_centrality'\n",
      " 'PRI_tau_pt' 'PRI_tau_eta' 'PRI_tau_phi' 'PRI_lep_pt' 'PRI_lep_eta'\n",
      " 'PRI_lep_phi' 'PRI_met' 'PRI_met_phi' 'PRI_met_sumet' 'PRI_jet_num'\n",
      " 'PRI_jet_leading_pt' 'PRI_jet_leading_eta' 'PRI_jet_leading_phi'\n",
      " 'PRI_jet_subleading_pt' 'PRI_jet_subleading_eta' 'PRI_jet_subleading_phi'\n",
      " 'PRI_jet_all_pt']\n",
      "(250000, 30)\n",
      "(250000, 30)\n",
      "Number of variables: 30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c50f0892abce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0marray_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marray_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m999\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marray_\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m999\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marray\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m999\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#n, bins, patches = plt.hist(array, 50)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "y_train, x_train, ids_train, headers = load_csv_data('data/train.csv')\n",
    "y_test, x_test, ids_test, headers_test = load_csv_data('data/test.csv')\n",
    "\n",
    "print(headers)\n",
    "\n",
    "x_train_extended = x_train.copy()\n",
    "x_train_extended = x_train_extended==-999\n",
    "\n",
    "\n",
    "print(x_train_extended.shape)\n",
    "print(x_train.shape)\n",
    "nbr_param = len(x_train[0])\n",
    "print(\"Number of variables: %i\"%(nbr_param))\n",
    "\n",
    "# Plot the histograms\n",
    "\n",
    "\n",
    "for i in range(len(x_train[0])):\n",
    "    array_ = x_train[:,i]\n",
    "    array = (standardize.standardize(array_[array_ != -999]))\n",
    "    x_train[array_!=-999,i] = array\n",
    "    n, bins, patches = plt.hist(array[array != -999], 250)\n",
    "    #n, bins, patches = plt.hist(array, 50)\n",
    "    plt.title(\"Variable %i: %s\"%(i, headers[i+2]))\n",
    "    plt.show()\n",
    "\n",
    "x_train_extended = np.concatenate((np.uint(x_train_extended),x_train),axis=1)\n",
    "print(x_train_extended.shape)\n",
    "print(x_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
